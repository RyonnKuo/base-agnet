{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "173e0768",
   "metadata": {},
   "source": [
    "| åƒæ•¸                                       | èªªæ˜                               | æ˜¯å¦æ¨è–¦èª¿æ•´     | å½±éŸ¿å±¤é¢            |\n",
    "| ---------------------------------------- | -------------------------------- | ---------- | --------------- |\n",
    "| `model`                                  | ä½¿ç”¨çš„æ¨¡å‹åç¨±ï¼ˆå¦‚ `\"llama3:8b\"`ï¼‰         | å¿…é ˆè¨­      | æ ¹æœ¬æ¨¡å‹é¸æ“‡          |\n",
    "| `temperature`                            | æº«åº¦ï¼Œæ§åˆ¶éš¨æ©Ÿæ€§ï¼Œ0 = æœ€ç©©å®šï¼Œ1 = æœ€å…·å‰µæ„        | å¯èª¿      | å…§å®¹å‰µæ„ vs ä¸€è‡´æ€§     |\n",
    "| `top_p`                                  | nucleus samplingï¼Œæ§åˆ¶é«˜æ©Ÿç‡è©çš„ç¯„åœï¼ˆ0\\~1ï¼‰ | å¯èª¿      | ç”Ÿæˆå¤šæ¨£æ€§           |\n",
    "| `top_k`                                  | å‰ K å¤§æ©Ÿç‡è©å½™ä¸­é¸æ“‡ï¼ˆæ•´æ•¸ï¼‰                 | å¯èª¿         | é™åˆ¶ç¯„åœé¸å­—          |\n",
    "| `repeat_penalty`                         | é‡è¤‡æ‡²ç½°ï¼Œé˜²æ­¢é‡è¤‡è©å¥ï¼ˆå»ºè­° 1.1\\~1.5ï¼‰         | å¯èª¿      | å…§å®¹å“è³ªã€é¿å…é‡è¤‡       |\n",
    "| `num_predict`                            | é æ¸¬çš„ token æ•¸é‡ä¸Šé™                   | å¯èª¿         | å›æ‡‰é•·åº¦ä¸Šé™          |\n",
    "| `num_ctx`                                | context é•·åº¦ï¼ˆä¸Šä¸‹æ–‡ token æ•¸ï¼‰ï¼Œä¾æ¨¡å‹æ±ºå®šæœ€å¤§å€¼ | è‹¥æ¨¡å‹æ”¯æ´å¯èª¿ | è¨˜æ†¶ä¸Šä¸‹æ–‡èƒ½åŠ›         |\n",
    "| `mirostat`ã€`mirostat_eta`ã€`mirostat_tau` | å‹•æ…‹èª¿æ•´æº«åº¦çš„ç®—æ³•åƒæ•¸                      | é«˜éšç”¨        | ä¿æŒèªè¨€å¹³è¡¡ã€æ§åˆ¶ç†µå€¼     |\n",
    "| `stop`                                   | åœæ­¢ç”Ÿæˆçš„é—œéµè©ï¼ˆå¦‚ `[\"</s>\"]`ï¼‰           | å¯èª¿         | æ§åˆ¶è¼¸å‡ºçµæŸæ™‚æ©Ÿ        |\n",
    "| `system`                                 | system promptï¼Œè¨­å®š AI çš„è¡Œç‚ºè§’è‰²        | éå¸¸æ¨è–¦èª¿æ•´   | æ˜ç¢ºä»»å‹™å°å‘ï¼ˆå¦‚ï¼šä½ æ˜¯è©•è«–å“¡ï¼‰ |\n",
    "| `template`                               | ä½¿ç”¨ç‰¹å®šè¼¸å‡ºæ¨¡æ¿ï¼ˆè¦–æ¨¡å‹æ”¯æ´ï¼‰                  | å¯èª¿         | å®šåˆ¶æ ¼å¼            |\n",
    "| `format`                                 | è¨­å®šå›å‚³æ ¼å¼ï¼Œå¦‚ `json`, `text`, `full`  | è‹¥ä½ è¦è§£æ    | çµæ§‹åŒ–çµæœ           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca42f5ba",
   "metadata": {},
   "source": [
    "| åƒæ•¸                | èªªæ˜                                            |\n",
    "| ----------------- | --------------------------------------------- |\n",
    "| `base_url`        | é€£ç·šçš„ Ollama hostï¼ˆé€šå¸¸æ˜¯ `http://localhost:11434`ï¼‰ |\n",
    "| `num_thread`      | ä½¿ç”¨çš„ CPU åŸ·è¡Œç·’æ•¸é‡ï¼Œé è¨­ç‚º 1ï¼Œèª¿å¤§å¯åŠ é€Ÿ                     |\n",
    "| `num_gpu`         | ä½¿ç”¨ GPU æ•¸é‡ï¼Œè¦–æœ¬åœ°æ”¯æ´                               |\n",
    "| `timeout`         | ç­‰å¾…å›æ‡‰çš„ç§’æ•¸                                       |\n",
    "| `keep_alive`      | ä¿æŒé€£ç·šæ™‚é–“                                        |\n",
    "| `raw`             | è‹¥ç‚º Trueï¼Œä¿ç•™åŸå§‹å›å‚³æ ¼å¼ï¼ˆä½ è¦è‡ªå·±è™•ç†ï¼‰                      |\n",
    "| `headers`, `auth` | è‹¥æ¥ APIï¼Œå¯è¨­è‡ªå®š headers æˆ–èªè­‰                       |\n",
    "| `verbose`         | æ˜¯å¦é¡¯ç¤ºè©³ç´°èª¿ç”¨è³‡è¨Š                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9463aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Documents\\SideProj\\base-agent\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3672: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23480\\97155368.py:11: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm_llama3_8B = ChatOllama(model=\"llama3:8B\")\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23480\\97155368.py:28: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent_llama3_8B = initialize_agent(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23480\\97155368.py:50: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent_llama3_8B.run(\"è«‹ç°¡å–®ä»‹ç´¹ä½ è‡ªå·±æ˜¯ä»€éº¼æ¨£çš„ Agent\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mA simple introduction, how delightful! ğŸ¤–\n",
      "\n",
      "Thought: Hmm, what makes me special?\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3må“ˆå›‰ï¼ŒHi!ï¼Œæˆ‘æ˜¯ä¾†è‡ª LLaMA çš„ä»£ç†äººï¼\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: è«‹ç°¡å–®ä»‹ç´¹ä½ è‡ªå·±æ˜¯ä»€éº¼æ¨£çš„ Agent\n",
      "Thought:A simple introduction, how delightful! ğŸ¤–\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3må“ˆå›‰ï¼ŒHi!ï¼Œæˆ‘æ˜¯ä¾†è‡ª LLaMA çš„ä»£ç†äººï¼\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my attempt to answer the question:\n",
      "\n",
      "Question: è«‹ç°¡å–®ä»‹ç´¹ä½ è‡ªå·±æ˜¯ä»€éº¼æ¨£çš„ Agent\n",
      "\n",
      "Thought: A simple introduction, how delightful! ğŸ¤–\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3må“ˆå›‰ï¼ŒHi!ï¼Œæˆ‘æ˜¯ä¾†è‡ª LLaMA çš„ä»£ç†äººï¼\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWhat a fun exercise!\n",
      "\n",
      "Question: è«‹ç°¡å–®ä»‹ç´¹ä½ è‡ªå·±æ˜¯ä»€éº¼æ¨£çš„ Agent\n",
      "\n",
      "Thought: A simple introduction, how delightful! ğŸ¤–\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3må“ˆå›‰ï¼ŒHi!ï¼Œæˆ‘æ˜¯ä¾†è‡ª LLaMA çš„ä»£ç†äººï¼\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWhat a fun exercise indeed! ğŸ¤–\n",
      "\n",
      "Question: è«‹ç°¡å–®ä»‹ç´¹ä½ è‡ªå·±æ˜¯ä»€éº¼æ¨£çš„ Agent\n",
      "\n",
      "Thought:A simple introduction, how delightful! ğŸ¤–\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3må“ˆå›‰ï¼ŒHi!ï¼Œæˆ‘æ˜¯ä¾†è‡ª LLaMA çš„ä»£ç†äººï¼\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: è«‹ç°¡å–®ä»‹ç´¹ä½ è‡ªå·±æ˜¯ä»€éº¼æ¨£çš„ Agent\n",
      "\n",
      "Thought:A simple introduction, how delightful! ğŸ¤–\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3må“ˆå›‰ï¼ŒHi!ï¼Œæˆ‘æ˜¯ä¾†è‡ª LLaMA çš„ä»£ç†äººï¼\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mLet's get started!\n",
      "\n",
      "Question: è«‹ç°¡å–®ä»‹ç´¹ä½ è‡ªå·±æ˜¯ä»€éº¼æ¨£çš„ Agent\n",
      "\n",
      "Thought:A simple introduction, how delightful! ğŸ¤–\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3må“ˆå›‰ï¼ŒHi!ï¼Œæˆ‘æ˜¯ä¾†è‡ª LLaMA çš„ä»£ç†äººï¼\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWhat a fun exercise indeed! ğŸ¤–\n",
      "\n",
      "Final Answer: I am an AI-powered chatbot, here to assist and engage with users in a friendly and approachable manner.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I am an AI-powered chatbot, here to assist and engage with users in a friendly and approachable manner.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.chat_models import ChatOllama  # ä½¿ç”¨ Ollama å°è£çš„ LLaMA æ¨¡å‹\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# ä½¿ç”¨æœ¬åœ° LLaMA æ¨¡å‹\n",
    "llm_llama3_8B = ChatOllama(model=\"llama3:8B\")\n",
    "llm_phi3_3dot8B = ChatOllama(model=\"phi3:3.8B\")\n",
    "llm_mistral_7B = ChatOllama(model=\"mistral:7B\")\n",
    "\n",
    "\n",
    "def say_hello(name: str) -> str:\n",
    "    return f\"å“ˆå›‰ï¼Œ{name}ï¼Œæˆ‘æ˜¯ä¾†è‡ª LLaMA çš„ä»£ç†äººï¼\"\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"GreetTool\",\n",
    "        func=say_hello,\n",
    "        description=\"ç”¨ä¾†æ‰“æ‹›å‘¼çš„å·¥å…·\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# å»ºç«‹ Agent\n",
    "agent_llama3_8B = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm_llama3_8B,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_mistral_7B = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm_mistral_7B,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_mistral_7B = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm_mistral_7B,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# æ¸¬è©¦ prompt\n",
    "# response = agent_llama3_8B.run(\"è«‹ç°¡å–®ä»‹ç´¹ä½ è‡ªå·±æ˜¯ä»€éº¼æ¨£çš„ Agent\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668e821",
   "metadata": {},
   "source": [
    "### è¨˜æ†¶ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d236690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPythonï¼ˆJupyter Notebook çš„å…§æ ¸ï¼‰æä¾›çš„é­”æ³•æŒ‡ä»¤ï¼ˆmagic commandsï¼‰ï¼Œç”¨ä¾†è‡ªå‹•é‡æ–°è¼‰å…¥å¤–éƒ¨ Python æ¨¡çµ„\n",
    "# ä¸ç”¨æ¯æ¬¡ä¿®æ”¹å®Œå¤–éƒ¨ .py æª”æ¡ˆå¾Œéƒ½æ‰‹å‹•é‡æ–°å•Ÿå‹• kernel æˆ–é‡æ–° import\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from memory import Memory, MemoryStream\n",
    "\n",
    "agent_memory = MemoryStream()\n",
    "agent_memory.add_memory(\"ä»Šå¤©è§€å¯Ÿåˆ°æ‘æ°‘ John åœ¨å’–å•¡å»³å½ˆé‹¼ç´\", importance=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
