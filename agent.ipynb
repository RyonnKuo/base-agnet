{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "173e0768",
   "metadata": {},
   "source": [
    "| 參數                                       | 說明                               | 是否推薦調整     | 影響層面            |\n",
    "| ---------------------------------------- | -------------------------------- | ---------- | --------------- |\n",
    "| `model`                                  | 使用的模型名稱（如 `\"llama3:8b\"`）         | 必須設      | 根本模型選擇          |\n",
    "| `temperature`                            | 溫度，控制隨機性，0 = 最穩定，1 = 最具創意        | 可調      | 內容創意 vs 一致性     |\n",
    "| `top_p`                                  | nucleus sampling，控制高機率詞的範圍（0\\~1） | 可調      | 生成多樣性           |\n",
    "| `top_k`                                  | 前 K 大機率詞彙中選擇（整數）                 | 可調         | 限制範圍選字          |\n",
    "| `repeat_penalty`                         | 重複懲罰，防止重複詞句（建議 1.1\\~1.5）         | 可調      | 內容品質、避免重複       |\n",
    "| `num_predict`                            | 預測的 token 數量上限                   | 可調         | 回應長度上限          |\n",
    "| `num_ctx`                                | context 長度（上下文 token 數），依模型決定最大值 | 若模型支援可調 | 記憶上下文能力         |\n",
    "| `mirostat`、`mirostat_eta`、`mirostat_tau` | 動態調整溫度的算法參數                      | 高階用        | 保持語言平衡、控制熵值     |\n",
    "| `stop`                                   | 停止生成的關鍵詞（如 `[\"</s>\"]`）           | 可調         | 控制輸出結束時機        |\n",
    "| `system`                                 | system prompt，設定 AI 的行為角色        | 非常推薦調整   | 明確任務導向（如：你是評論員） |\n",
    "| `template`                               | 使用特定輸出模板（視模型支援）                  | 可調         | 定制格式            |\n",
    "| `format`                                 | 設定回傳格式，如 `json`, `text`, `full`  | 若你要解析    | 結構化結果           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca42f5ba",
   "metadata": {},
   "source": [
    "| 參數                | 說明                                            |\n",
    "| ----------------- | --------------------------------------------- |\n",
    "| `base_url`        | 連線的 Ollama host（通常是 `http://localhost:11434`） |\n",
    "| `num_thread`      | 使用的 CPU 執行緒數量，預設為 1，調大可加速                     |\n",
    "| `num_gpu`         | 使用 GPU 數量，視本地支援                               |\n",
    "| `timeout`         | 等待回應的秒數                                       |\n",
    "| `keep_alive`      | 保持連線時間                                        |\n",
    "| `raw`             | 若為 True，保留原始回傳格式（你要自己處理）                      |\n",
    "| `headers`, `auth` | 若接 API，可設自定 headers 或認證                       |\n",
    "| `verbose`         | 是否顯示詳細調用資訊                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9463aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Documents\\SideProj\\base-agent\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3672: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23480\\97155368.py:11: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm_llama3_8B = ChatOllama(model=\"llama3:8B\")\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23480\\97155368.py:28: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent_llama3_8B = initialize_agent(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23480\\97155368.py:50: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent_llama3_8B.run(\"請簡單介紹你自己是什麼樣的 Agent\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mA simple introduction, how delightful! 🤖\n",
      "\n",
      "Thought: Hmm, what makes me special?\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m哈囉，Hi!，我是來自 LLaMA 的代理人！\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: 請簡單介紹你自己是什麼樣的 Agent\n",
      "Thought:A simple introduction, how delightful! 🤖\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m哈囉，Hi!，我是來自 LLaMA 的代理人！\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my attempt to answer the question:\n",
      "\n",
      "Question: 請簡單介紹你自己是什麼樣的 Agent\n",
      "\n",
      "Thought: A simple introduction, how delightful! 🤖\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m哈囉，Hi!，我是來自 LLaMA 的代理人！\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWhat a fun exercise!\n",
      "\n",
      "Question: 請簡單介紹你自己是什麼樣的 Agent\n",
      "\n",
      "Thought: A simple introduction, how delightful! 🤖\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m哈囉，Hi!，我是來自 LLaMA 的代理人！\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWhat a fun exercise indeed! 🤖\n",
      "\n",
      "Question: 請簡單介紹你自己是什麼樣的 Agent\n",
      "\n",
      "Thought:A simple introduction, how delightful! 🤖\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m哈囉，Hi!，我是來自 LLaMA 的代理人！\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: 請簡單介紹你自己是什麼樣的 Agent\n",
      "\n",
      "Thought:A simple introduction, how delightful! 🤖\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m哈囉，Hi!，我是來自 LLaMA 的代理人！\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mLet's get started!\n",
      "\n",
      "Question: 請簡單介紹你自己是什麼樣的 Agent\n",
      "\n",
      "Thought:A simple introduction, how delightful! 🤖\n",
      "\n",
      "Action: GreetTool\n",
      "Action Input: Hi!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m哈囉，Hi!，我是來自 LLaMA 的代理人！\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWhat a fun exercise indeed! 🤖\n",
      "\n",
      "Final Answer: I am an AI-powered chatbot, here to assist and engage with users in a friendly and approachable manner.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I am an AI-powered chatbot, here to assist and engage with users in a friendly and approachable manner.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.chat_models import ChatOllama  # 使用 Ollama 封裝的 LLaMA 模型\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# 使用本地 LLaMA 模型\n",
    "llm_llama3_8B = ChatOllama(model=\"llama3:8B\")\n",
    "llm_phi3_3dot8B = ChatOllama(model=\"phi3:3.8B\")\n",
    "llm_mistral_7B = ChatOllama(model=\"mistral:7B\")\n",
    "\n",
    "\n",
    "def say_hello(name: str) -> str:\n",
    "    return f\"哈囉，{name}，我是來自 LLaMA 的代理人！\"\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"GreetTool\",\n",
    "        func=say_hello,\n",
    "        description=\"用來打招呼的工具\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 建立 Agent\n",
    "agent_llama3_8B = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm_llama3_8B,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_mistral_7B = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm_mistral_7B,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_mistral_7B = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm_mistral_7B,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 測試 prompt\n",
    "# response = agent_llama3_8B.run(\"請簡單介紹你自己是什麼樣的 Agent\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668e821",
   "metadata": {},
   "source": [
    "### 記憶 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d236690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython（Jupyter Notebook 的內核）提供的魔法指令（magic commands），用來自動重新載入外部 Python 模組\n",
    "# 不用每次修改完外部 .py 檔案後都手動重新啟動 kernel 或重新 import\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from memory import Memory, MemoryStream\n",
    "\n",
    "agent_memory = MemoryStream()\n",
    "agent_memory.add_memory(\"今天觀察到村民 John 在咖啡廳彈鋼琴\", importance=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
